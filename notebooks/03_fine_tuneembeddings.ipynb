{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING! This Notebook uses a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 22 20:38:31 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 6000 Ada Gene...    On  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 30%   37C    P8              22W / 300W |      1MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Quick fix to use package from external instance with GPU\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import InputExample, SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "\n",
    "from src.data import load_data\n",
    "from src.evaluation import naive_map_at_k, apply_weighted_map\n",
    "from src.fine_tuning import create_product_dict, create_query_dict, create_relevance_dict, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that will be used in the notebook\n",
    "DATA_PATH: Path = Path(\"../data\")\n",
    "SEED: int = 1399"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryDF: Rows [480], Columns: [3]\n",
      "ProductDF: Rows [42,994], Columns: [9]\n",
      "LabelDF: Rows [233,448], Columns: [4]\n"
     ]
    }
   ],
   "source": [
    "# Load all the dataframes\n",
    "query_df: pd.DataFrame\n",
    "product_df: pd.DataFrame\n",
    "label_df: pd.DataFrame\n",
    "query_df, product_df, label_df= load_data(datapath=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id: str = \"Snowflake/snowflake-arctic-embed-l\"\n",
    "model: SentenceTransformer = SentenceTransformer(model_name_or_path=model_id, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries, Corpus and Relevant Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create queries (query_id, query), corpus (product_id, product_name) and relevant_documents (exact matches) dictionaries.\n",
    "queries: dict[str, str]\n",
    "corpus: dict[str, str]\n",
    "relevant_documents: dict[str, list[str]]\n",
    "queries, corpus, relevant_documents = prepare_data(query_df=query_df, product_df=product_df, label_df=label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 42994, 379)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(corpus), len(relevant_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries: list[str]\n",
    "test_queries: list[str]\n",
    "train_queries, test_queries = train_test_split(list(queries.keys()), test_size=0.2, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries_dict: dict[str, str]\n",
    "test_queries_dict: dict[str, str]\n",
    "train_queries_dict, test_queries_dict = {k: queries[k] for k in train_queries}, {k: queries[k] for k in test_queries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_relevant_documents: dict[str, list[str]]\n",
    "test_relevant_documents: dict[str, list[str]]\n",
    "train_relevant_documents, test_relevant_documents = {k: relevant_documents[k] for k in train_queries if k in relevant_documents}, {k: relevant_documents[k] for k in test_queries if k in relevant_documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train input examples\n",
    "examples: list[InputExample] = []\n",
    "for query_id, query in train_queries_dict.items():\n",
    "    if query_id in train_relevant_documents:\n",
    "        for product_id in train_relevant_documents[query_id]:\n",
    "            examples.append(InputExample(texts=[query, corpus[product_id]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader\n",
    "BATCH_SIZE: int = 128\n",
    "loader: DataLoader = DataLoader(dataset=examples, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss and Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator: InformationRetrievalEvaluator = InformationRetrievalEvaluator(\n",
    "    queries=test_queries_dict,\n",
    "    corpus=corpus,\n",
    "    relevant_docs=test_relevant_documents,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 03:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cosine Accuracy@1</th>\n",
       "      <th>Cosine Accuracy@3</th>\n",
       "      <th>Cosine Accuracy@5</th>\n",
       "      <th>Cosine Accuracy@10</th>\n",
       "      <th>Cosine Precision@1</th>\n",
       "      <th>Cosine Precision@3</th>\n",
       "      <th>Cosine Precision@5</th>\n",
       "      <th>Cosine Precision@10</th>\n",
       "      <th>Cosine Recall@1</th>\n",
       "      <th>Cosine Recall@3</th>\n",
       "      <th>Cosine Recall@5</th>\n",
       "      <th>Cosine Recall@10</th>\n",
       "      <th>Cosine Ndcg@10</th>\n",
       "      <th>Cosine Mrr@10</th>\n",
       "      <th>Cosine Map@100</th>\n",
       "      <th>Dot Accuracy@1</th>\n",
       "      <th>Dot Accuracy@3</th>\n",
       "      <th>Dot Accuracy@5</th>\n",
       "      <th>Dot Accuracy@10</th>\n",
       "      <th>Dot Precision@1</th>\n",
       "      <th>Dot Precision@3</th>\n",
       "      <th>Dot Precision@5</th>\n",
       "      <th>Dot Precision@10</th>\n",
       "      <th>Dot Recall@1</th>\n",
       "      <th>Dot Recall@3</th>\n",
       "      <th>Dot Recall@5</th>\n",
       "      <th>Dot Recall@10</th>\n",
       "      <th>Dot Ndcg@10</th>\n",
       "      <th>Dot Mrr@10</th>\n",
       "      <th>Dot Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.431169</td>\n",
       "      <td>0.049945</td>\n",
       "      <td>0.093425</td>\n",
       "      <td>0.123041</td>\n",
       "      <td>0.193934</td>\n",
       "      <td>0.512839</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>0.387754</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.502165</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.431169</td>\n",
       "      <td>0.049945</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.123041</td>\n",
       "      <td>0.193934</td>\n",
       "      <td>0.512267</td>\n",
       "      <td>0.636936</td>\n",
       "      <td>0.387759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.459740</td>\n",
       "      <td>0.433766</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>0.093165</td>\n",
       "      <td>0.111268</td>\n",
       "      <td>0.183292</td>\n",
       "      <td>0.507680</td>\n",
       "      <td>0.632210</td>\n",
       "      <td>0.377196</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.459740</td>\n",
       "      <td>0.433766</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>0.093165</td>\n",
       "      <td>0.111268</td>\n",
       "      <td>0.183292</td>\n",
       "      <td>0.507680</td>\n",
       "      <td>0.632210</td>\n",
       "      <td>0.377196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434ee44ac4ca4908a868a25ef116dd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:26<00:00, 26.09s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3ac8e57c5b4cd98ba1cf7cb8100886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:26<00:00, 26.05s/it]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='finetuned_model',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate queries embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9848590dd6a437bb1d57f7df3298f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries_embeddings: np.ndarray = model.encode(\n",
    "    sentences=query_df[\"query\"].to_list(),\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 1024)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating product names embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699133b8bef14f1a88656eaf8762c674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "product_names_embeddings: np.ndarray = model.encode(\n",
    "    sentences=product_df[\"product_name\"].tolist(),\n",
    "    batch_size=128,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42994, 1024)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_names_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 42994)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarities for all queries\n",
    "cosine_similarities: np.ndarray = cosine_similarity(X=queries_embeddings, Y=product_names_embeddings)\n",
    "cosine_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 predictions for each query\n",
    "top_10_indices: np.ndarray = np.argpartition(a=cosine_similarities, kth=-10, axis=1)[:, -10:]\n",
    "top_10_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the top 10 predictions by similarity score\n",
    "top_10_sorted: np.ndarray = np.array([row[np.argsort(-cosine_similarities[i, row])] for i, row in enumerate(top_10_indices)])\n",
    "top_10_sorted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate MAP@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preds and actual values \n",
    "query_df[\"preds\"] = top_10_sorted.tolist()\n",
    "\n",
    "query_df = query_df.merge(\n",
    "    how=\"left\",\n",
    "    right=label_df[label_df[\"label\"] == \"Exact\"].groupby(by=\"query_id\")[\"product_id\"].unique().rename(\"actuals_exact\"),\n",
    "    left_on=\"query_id\",\n",
    "    right_index=True\n",
    ")\n",
    "query_df[\"actuals_exact\"] = query_df[\"actuals_exact\"].fillna(\"\").apply(list)\n",
    "\n",
    "query_df = query_df.merge(\n",
    "    how=\"left\",\n",
    "    right=label_df[label_df[\"label\"].isin([\"Exact\", \"Partial\"])].groupby(by=\"query_id\")[\"product_id\"].unique().rename(\"actuals\"),\n",
    "    left_on=\"query_id\",\n",
    "    right_index=True\n",
    ")\n",
    "query_df[\"actuals\"] = query_df[\"actuals\"].fillna(\"\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive MAP@K: 0.39397622492283957\n"
     ]
    }
   ],
   "source": [
    "# Calculate naive map@10\n",
    "query_df['map@k'] = query_df.apply(lambda x: naive_map_at_k(x['actuals_exact'], x['preds'], k=10), axis=1)\n",
    "print(f\"Naive MAP@K: {query_df.loc[:, 'map@k'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted MAP@K: 0.6125091903659611\n"
     ]
    }
   ],
   "source": [
    "query_df['weighted_map@k'] = query_df.apply(lambda x: apply_weighted_map(row=x, label_df=label_df, k=10, partial_weight=0.5), axis=1)\n",
    "weighted_map_at_k_score = query_df['weighted_map@k'].mean()\n",
    "print(f\"Weighted MAP@K: {weighted_map_at_k_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
