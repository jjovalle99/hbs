{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from openai import AsyncOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from src.data import load_data\n",
    "from src.evaluation import naive_map_at_k, weighted_map_at_k\n",
    "from src.settings import Settings\n",
    "from src.utils import gen_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that will be used in the notebook\n",
    "DATA_PATH: Path = Path(\"../data\")\n",
    "SETTINGS: Settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryDF: Rows [480], Columns: [3]\n",
      "ProductDF: Rows [42,994], Columns: [9]\n",
      "LabelDF: Rows [233,448], Columns: [4]\n"
     ]
    }
   ],
   "source": [
    "# Load all the dataframes\n",
    "query_df: pd.DataFrame\n",
    "product_df: pd.DataFrame\n",
    "label_df: pd.DataFrame\n",
    "query_df, product_df, label_df= load_data(datapath=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost expectation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tiktoken, we can calculate the cost of the embeddings\n",
    "embedding_model: str = \"text-embedding-3-large\"\n",
    "tokenizer: tiktoken.Encoding = tiktoken.encoding_for_model(model_name=embedding_model)\n",
    "price_per_million_tokens: float = 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of generating the embeddings of all the products: 0.05395585 USD\n"
     ]
    }
   ],
   "source": [
    "total_cost: float = (len(tokenizer.encode(text=\"\".join(product_df[\"product_name\"].tolist()))) * price_per_million_tokens) / 1e6\n",
    "print(f\"Cost of generating the embeddings of all the products: {total_cost} USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of generating the embeddings of all the queries: 0.00029263 USD\n"
     ]
    }
   ],
   "source": [
    "total_cost: float = (len(tokenizer.encode(text=\"\".join(query_df[\"query\"].tolist()))) * price_per_million_tokens) / 1e6\n",
    "print(f\"Cost of generating the embeddings of all the queries: {total_cost} USD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define OpenAI asynchronous client\n",
    "client: AsyncOpenAI = AsyncOpenAI(api_key=SETTINGS.openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating product names embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embeddings of products are going to be generated in batches because there are more than 40k products \n",
    "product_names_embeddings: list = []\n",
    "batch_size: int = 1_024\n",
    "total: int = len(product_df[\"product_name\"].tolist()) // batch_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20/42 processing...\n",
      "Batch 20/42 done!\n",
      "Batch 40/42 processing...\n",
      "Batch 40/42 done!\n",
      "Batch 42/42 processing...\n",
      "Batch 42/42 done!\n"
     ]
    }
   ],
   "source": [
    "# Batch execution\n",
    "for idx, batch in enumerate(gen_batches(iterable=product_df[\"product_name\"].tolist(), n=batch_size), start=1):\n",
    "\n",
    "    if any([idx % 20 == 0, idx // total == 1]):\n",
    "        print(f\"Batch {idx}/{total} processing...\")\n",
    "\n",
    "    vectors: list = await client.embeddings.create(\n",
    "        model=embedding_model,\n",
    "        input=batch\n",
    "    )\n",
    "    product_names_embeddings.extend([embedding.embedding for embedding in vectors.data])\n",
    "\n",
    "    if any([idx % 20 == 0, idx // total == 1]):\n",
    "        print(f\"Batch {idx}/{total} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42994, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert embeddings to numpy arrays\n",
    "product_names_embeddings: np.ndarray = np.array(object=product_names_embeddings)\n",
    "product_names_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate queries embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 3072)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Queries embeddings\n",
    "vectors = await client.embeddings.create(model=embedding_model, input=query_df[\"query\"].to_list())\n",
    "queries_embeddings: np.ndarray = np.array(object=[embedding.embedding for embedding in vectors.data])\n",
    "queries_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 42994)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarities for all queries\n",
    "cosine_similarities: np.ndarray = cosine_similarity(X=queries_embeddings, Y=product_names_embeddings)\n",
    "cosine_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 predictions for each query\n",
    "top_10_indices: np.ndarray = np.argpartition(a=cosine_similarities, kth=-10, axis=1)[:, -10:]\n",
    "top_10_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the top 10 predictions by similarity score\n",
    "top_10_sorted: np.ndarray = np.array([row[np.argsort(-cosine_similarities[i, row])] for i, row in enumerate(top_10_indices)])\n",
    "top_10_sorted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate MAP@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preds and actual values \n",
    "query_df[\"preds\"] = top_10_sorted.tolist()\n",
    "\n",
    "query_df = query_df.merge(\n",
    "    how=\"left\",\n",
    "    right=label_df[label_df[\"label\"] == \"Exact\"].groupby(by=\"query_id\")[\"product_id\"].unique().rename(\"actuals_exact\"),\n",
    "    left_on=\"query_id\",\n",
    "    right_index=True\n",
    ")\n",
    "query_df = query_df.merge(\n",
    "    how=\"left\",\n",
    "    right=label_df.groupby(by=\"query_id\")[\"product_id\"].unique().rename(\"actuals\"),\n",
    "    left_on=\"query_id\",\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[\"actuals_exact\"] = query_df[\"actuals_exact\"].fillna(\"\").apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38698099233906524"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate naive map@10\n",
    "query_df['map@k'] = query_df.apply(lambda x: naive_map_at_k(x['actuals_exact'], x['preds'], k=10), axis=1)\n",
    "query_df.loc[:, 'map@k'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weighted_map(row, label_df, k=10, partial_weight=0.5):\n",
    "    return weighted_map_at_k(query_id=row['query_id'], true_ids=row[\"actuals\"], predicted_ids=row['preds'], label_df=label_df, k=k, partial_weight=partial_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted MAP@K: 0.5927448330026456\n"
     ]
    }
   ],
   "source": [
    "query_df['weighted_map@k'] = query_df.apply(lambda x: apply_weighted_map(row=x, label_df=label_df, k=10, partial_weight=0.5), axis=1)\n",
    "weighted_map_at_k_score = query_df['weighted_map@k'].mean()\n",
    "print(f\"Weighted MAP@K: {weighted_map_at_k_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
